from game import MDPGame, medium_level
from dynamic_programming import value_iteration, policy_iteration
from monte_carlo import mc_epsilon_greedy
from tuning import TuningParameters, test_hyperparameters, extract_hyperparameters, plot_hyperparameters
from q_learning import q_learning
from sarsa import sarsa
from utils import print_policy, test_policy, Q_to_policy
import sys

if __name__ == "__main__":
    args = sys.argv

    n = 5 # default n value
    env = MDPGame(random_x=True)
    env.load_level(medium_level)

    if "-n" in args:
        n = int(args[args.index("-n") + 1])


    # Dynamic Programming
    policy, V = value_iteration(env, gamma=0.95, theta=1e-10)
    print("policy generated by value iteration: ")
    test_policy(policy, env)
    print_policy(policy, env)

    policy, V = policy_iteration(env, gamma=0.95, theta=1e-10)
    print("policy generated by value iteration: ")
    test_policy(policy, env)
    print_policy(policy, env)

    # monte carlo
    print(f"Testing montecarlo methods {n} times: ")
    df = test_hyperparameters(env, n, TuningParameters.mc_epsilon_greedy, mc_epsilon_greedy)
    plot_hyperparameters(df, "monte_carlo")
    ideal_params = extract_hyperparameters(df)
    print(f"ideal hyperparameters found {ideal_params}")
    print("policy generated by montecarlo methods, using ideal parameters: ")

    params = {**ideal_params, "env": env}
    params.pop("pass_rate") # not an input parameter
    Q = mc_epsilon_greedy(**params)
    policy = Q_to_policy(Q, env)
    test_policy(policy, env)
    print_policy(policy, env)

    # sarsa
    print(f"Testing SARSA {n} times: ")
    df = test_hyperparameters(env, n, TuningParameters.sarsa, sarsa)
    plot_hyperparameters(df, "sarsa")
    ideal_params = extract_hyperparameters(df)
    print(f"ideal hyperparameters found {ideal_params}")
    print("policy generated by SARSA, using ideal parameters: ")

    params = {**ideal_params, "env": env}
    params.pop("pass_rate") # not an input parameter
    Q = sarsa(**params)
    policy = Q_to_policy(Q, env)
    test_policy(policy, env)
    print_policy(policy, env)

    # q-learning
    print(f"Testing Q-learning {n} times: ")
    df = test_hyperparameters(env, n, TuningParameters.q_learning, q_learning)
    plot_hyperparameters(df, "sarsa")
    ideal_params = extract_hyperparameters(df)
    print(f"ideal hyperparameters found {ideal_params}")
    print("policy generated by SARSA, using ideal parameters: ")

    params = {**ideal_params, "env": env}
    params.pop("pass_rate") # not an input parameter
    Q = q_learning(**params)
    policy = Q_to_policy(Q, env)
    test_policy(policy, env)
    print_policy(policy, env)